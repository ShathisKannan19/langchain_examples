{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools using the langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\"\"\"\n",
    "Initialize the chatbot model\n",
    "\n",
    "Here we using the ChatGroq class from langchain_groq module to initialize the chatbot model.\n",
    "The model is llama3-70b-8192 which is trained on the llama3 dataset with 70 billion parameters.\n",
    "The temperature is set to 0 which means the model will always return the most probable token.\n",
    "The max_tokens is set to None which means the model will generate as many tokens as it wants.\n",
    "The timeout is set to None which means the model will not timeout.\n",
    "The max_retries is set to 2 which means the model will retry 2 times if the request fails.\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-70b-8192\",temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"\n",
    "    Returns the length of the word\n",
    "    \n",
    "    Args:\n",
    "        word (str): The word to be processed\n",
    "        \n",
    "    Returns:\n",
    "        int: The length of the word\n",
    "    \"\"\"\n",
    "    return len(word)\n",
    "\n",
    "@tool\n",
    "def get_word_count(word: str) -> int:\n",
    "    \"\"\"\n",
    "    Returns the count of the words\n",
    "    \n",
    "    Args:\n",
    "        word (str): The word to be processed\n",
    "        \n",
    "    Returns:\n",
    "        int: The count of the words\n",
    "    \"\"\"\n",
    "    word_len = word.split(\" \")\n",
    "    return len(word_len)\n",
    "\n",
    "get_word_count.invoke(\"Shathis Kannan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make the tools available to the chatbot\n",
    "\"\"\"\n",
    "tools = [get_word_length,get_word_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the ChatPromptTemplate and MessagesPlaceholder from langchain_core.prompts for creating the chat prompt\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\"\"\"\n",
    "Create the chat prompt\n",
    "\n",
    "Here we are creating a chat prompt using the ChatPromptTemplate class from langchain_core.prompts module.\n",
    "The chat prompt is a list of messages that the chatbot will use to interact with the user.\n",
    "The ChatPromptTemplate.from_messages method is used to create the chat prompt.\n",
    "The first message is from the system which says \"You are very powerful assistant, but don't know current events\".\n",
    "The second message is from the user which is the input message.\n",
    "The third message is a placeholder for the agent scratchpad which is used to store the intermediate values of the agent.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but don't know current events\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bind the tools to the chatbot model\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Langchain agent pipeline for the chatbot\n",
    "\n",
    "Here we are creating a langchain agent pipeline for the chatbot.\n",
    "The agent pipeline is created using the langchain agent pipeline operator.\n",
    "The agent pipeline is a composition of the following functions:\n",
    "1. The input message is passed to the chatbot model.\n",
    "2. The intermediate steps are passed to the agent scratchpad.\n",
    "3. The output of the chatbot model is passed to the output parser.\n",
    "\"\"\"\n",
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Create the agent executor\n",
    "\"\"\"\n",
    "Create the agent executor\n",
    "\n",
    "Here we are creating the agent executor for the chatbot.\n",
    "The agent executor is created using the AgentExecutor class from langchain agents module.\n",
    "The agent executor is used to execute the agent pipeline.\n",
    "The agent executor takes the agent and tools as input.\n",
    "The verbose parameter is set to True which means the agent executor will print the output.\n",
    "\"\"\"\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_count` with `{'word': \"In this case we're relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been specifically trained to know when to invoke those tools. To pass in our tools to the agent, we just need to format them to the OpenAI tool format and pass them to our model. (By bind-ing the functions, we're making sure that they're passed in each time the model is invoked.)\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m71\u001b[0m\u001b[32;1m\u001b[1;3mThe word count for the given paragraph is 71.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'actions': [ToolAgentAction(tool='get_word_count', tool_input={'word': \"In this case we're relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been specifically trained to know when to invoke those tools. To pass in our tools to the agent, we just need to format them to the OpenAI tool format and pass them to our model. (By bind-ing the functions, we're making sure that they're passed in each time the model is invoked.)\"}, log='\\nInvoking: `get_word_count` with `{\\'word\\': \"In this case we\\'re relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been specifically trained to know when to invoke those tools. To pass in our tools to the agent, we just need to format them to the OpenAI tool format and pass them to our model. (By bind-ing the functions, we\\'re making sure that they\\'re passed in each time the model is invoked.)\"}`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_c4h4', 'function': {'arguments': '{\"word\":\"In this case we\\'re relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been specifically trained to know when to invoke those tools. To pass in our tools to the agent, we just need to format them to the OpenAI tool format and pass them to our model. (By bind-ing the functions, we\\'re making sure that they\\'re passed in each time the model is invoked.)\"}', 'name': 'get_word_count'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-192492ab-a51f-47b1-ae1d-c1128dbe0802', tool_calls=[{'name': 'get_word_count', 'args': {'word': \"In this case we're relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been specifically trained to know when to invoke those tools. To pass in our tools to the agent, we just need to format them to the OpenAI tool format and pass them to our model. (By bind-ing the functions, we're making sure that they're passed in each time the model is invoked.)\"}, 'id': 'call_c4h4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1169, 'output_tokens': 129, 'total_tokens': 1298}, tool_call_chunks=[{'name': 'get_word_count', 'args': '{\"word\":\"In this case we\\'re relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been specifically trained to know when to invoke those tools. To pass in our tools to the agent, we just need to format them to the OpenAI tool format and pass them to our model. (By bind-ing the functions, we\\'re making sure that they\\'re passed in each time the model is invoked.)\"}', 'id': 'call_c4h4', 'index': None, 'type': 'tool_call_chunk'}])], tool_call_id='call_c4h4')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_c4h4', 'function': {'arguments': '{\"word\":\"In this case we\\'re relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been specifically trained to know when to invoke those tools. To pass in our tools to the agent, we just need to format them to the OpenAI tool format and pass them to our model. (By bind-ing the functions, we\\'re making sure that they\\'re passed in each time the model is invoked.)\"}', 'name': 'get_word_count'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-192492ab-a51f-47b1-ae1d-c1128dbe0802', tool_calls=[{'name': 'get_word_count', 'args': {'word': \"In this case we're relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been specifically trained to know when to invoke those tools. To pass in our tools to the agent, we just need to format them to the OpenAI tool format and pass them to our model. (By bind-ing the functions, we're making sure that they're passed in each time the model is invoked.)\"}, 'id': 'call_c4h4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1169, 'output_tokens': 129, 'total_tokens': 1298}, tool_call_chunks=[{'name': 'get_word_count', 'args': '{\"word\":\"In this case we\\'re relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been specifically trained to know when to invoke those tools. To pass in our tools to the agent, we just need to format them to the OpenAI tool format and pass them to our model. (By bind-ing the functions, we\\'re making sure that they\\'re passed in each time the model is invoked.)\"}', 'id': 'call_c4h4', 'index': None, 'type': 'tool_call_chunk'}])]},\n",
       " {'steps': [AgentStep(action=ToolAgentAction(tool='get_word_count', tool_input={'word': \"In this case we're relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been specifically trained to know when to invoke those tools. To pass in our tools to the agent, we just need to format them to the OpenAI tool format and pass them to our model. (By bind-ing the functions, we're making sure that they're passed in each time the model is invoked.)\"}, log='\\nInvoking: `get_word_count` with `{\\'word\\': \"In this case we\\'re relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been specifically trained to know when to invoke those tools. To pass in our tools to the agent, we just need to format them to the OpenAI tool format and pass them to our model. (By bind-ing the functions, we\\'re making sure that they\\'re passed in each time the model is invoked.)\"}`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_c4h4', 'function': {'arguments': '{\"word\":\"In this case we\\'re relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been specifically trained to know when to invoke those tools. To pass in our tools to the agent, we just need to format them to the OpenAI tool format and pass them to our model. (By bind-ing the functions, we\\'re making sure that they\\'re passed in each time the model is invoked.)\"}', 'name': 'get_word_count'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-192492ab-a51f-47b1-ae1d-c1128dbe0802', tool_calls=[{'name': 'get_word_count', 'args': {'word': \"In this case we're relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been specifically trained to know when to invoke those tools. To pass in our tools to the agent, we just need to format them to the OpenAI tool format and pass them to our model. (By bind-ing the functions, we're making sure that they're passed in each time the model is invoked.)\"}, 'id': 'call_c4h4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1169, 'output_tokens': 129, 'total_tokens': 1298}, tool_call_chunks=[{'name': 'get_word_count', 'args': '{\"word\":\"In this case we\\'re relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been specifically trained to know when to invoke those tools. To pass in our tools to the agent, we just need to format them to the OpenAI tool format and pass them to our model. (By bind-ing the functions, we\\'re making sure that they\\'re passed in each time the model is invoked.)\"}', 'id': 'call_c4h4', 'index': None, 'type': 'tool_call_chunk'}])], tool_call_id='call_c4h4'), observation=71)],\n",
       "  'messages': [FunctionMessage(content='71', name='get_word_count')]},\n",
       " {'output': 'The word count for the given paragraph is 71.',\n",
       "  'messages': [AIMessage(content='The word count for the given paragraph is 71.')]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Execute the agent pipeline\n",
    "\n",
    "Here we are executing the agent pipeline using the agent executor.\n",
    "The agent executor takes the input message as input.\n",
    "The agent executor will return the output of the agent pipeline.\n",
    "\"\"\"\n",
    "list(agent_executor.stream({\"input\": \"\"\"\n",
    "                            Give the word count for the Below paragraph:\n",
    "                            In this case we're relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been\n",
    "                            specifically trained to know when to invoke those tools.\n",
    "                            To pass in our tools to the agent, we just need to format them to the OpenAI tool format and pass them to our model.\n",
    "                            (By bind-ing the functions, we're making sure that they're passed in each time the model is invoked.)\n",
    "                            \"\"\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'Shathis'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m7\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'Kannan'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m6\u001b[0m\u001b[32;1m\u001b[1;3mThe total number of letters in \"Shathis Kannan\" is 7 + 6 = 13.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'actions': [ToolAgentAction(tool='get_word_length', tool_input={'word': 'Shathis'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'Shathis'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_5tnn', 'function': {'arguments': '{\"word\":\"Shathis\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d2651b39-2291-4dd9-a49e-64373f68734a', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'Shathis'}, 'id': 'call_5tnn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1077, 'output_tokens': 46, 'total_tokens': 1123}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"Shathis\"}', 'id': 'call_5tnn', 'index': None, 'type': 'tool_call_chunk'}])], tool_call_id='call_5tnn')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_5tnn', 'function': {'arguments': '{\"word\":\"Shathis\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d2651b39-2291-4dd9-a49e-64373f68734a', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'Shathis'}, 'id': 'call_5tnn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1077, 'output_tokens': 46, 'total_tokens': 1123}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"Shathis\"}', 'id': 'call_5tnn', 'index': None, 'type': 'tool_call_chunk'}])]},\n",
       " {'steps': [AgentStep(action=ToolAgentAction(tool='get_word_length', tool_input={'word': 'Shathis'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'Shathis'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_5tnn', 'function': {'arguments': '{\"word\":\"Shathis\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d2651b39-2291-4dd9-a49e-64373f68734a', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'Shathis'}, 'id': 'call_5tnn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1077, 'output_tokens': 46, 'total_tokens': 1123}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"Shathis\"}', 'id': 'call_5tnn', 'index': None, 'type': 'tool_call_chunk'}])], tool_call_id='call_5tnn'), observation=7)],\n",
       "  'messages': [FunctionMessage(content='7', name='get_word_length')]},\n",
       " {'actions': [ToolAgentAction(tool='get_word_length', tool_input={'word': 'Kannan'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'Kannan'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_zyh0', 'function': {'arguments': '{\"word\":\"Kannan\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-786755be-5811-47a1-bff4-5a07e0633012', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'Kannan'}, 'id': 'call_zyh0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1146, 'output_tokens': 39, 'total_tokens': 1185}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"Kannan\"}', 'id': 'call_zyh0', 'index': None, 'type': 'tool_call_chunk'}])], tool_call_id='call_zyh0')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_zyh0', 'function': {'arguments': '{\"word\":\"Kannan\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-786755be-5811-47a1-bff4-5a07e0633012', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'Kannan'}, 'id': 'call_zyh0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1146, 'output_tokens': 39, 'total_tokens': 1185}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"Kannan\"}', 'id': 'call_zyh0', 'index': None, 'type': 'tool_call_chunk'}])]},\n",
       " {'steps': [AgentStep(action=ToolAgentAction(tool='get_word_length', tool_input={'word': 'Kannan'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'Kannan'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_zyh0', 'function': {'arguments': '{\"word\":\"Kannan\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-786755be-5811-47a1-bff4-5a07e0633012', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'Kannan'}, 'id': 'call_zyh0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1146, 'output_tokens': 39, 'total_tokens': 1185}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"Kannan\"}', 'id': 'call_zyh0', 'index': None, 'type': 'tool_call_chunk'}])], tool_call_id='call_zyh0'), observation=6)],\n",
       "  'messages': [FunctionMessage(content='6', name='get_word_length')]},\n",
       " {'output': 'The total number of letters in \"Shathis Kannan\" is 7 + 6 = 13.',\n",
       "  'messages': [AIMessage(content='The total number of letters in \"Shathis Kannan\" is 7 + 6 = 13.')]}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Execute the agent pipeline\n",
    "\n",
    "Here we are executing the agent pipeline using the agent executor.\n",
    "The agent executor takes the input message as input.\n",
    "The agent executor will return the output of the agent pipeline.\n",
    "\"\"\"\n",
    "result = llm.invoke(\"How many letters in the Shathis Kannan\")\n",
    "\n",
    "list(agent_executor.stream({\"input\": \"How many letters in the Shathis Kannan\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me count the letters for you!\n",
      "\n",
      "Here are the letters in \"Shathis Kannan\":\n",
      "\n",
      "1. S\n",
      "2. H\n",
      "3. A\n",
      "4. T\n",
      "5. H\n",
      "6. I\n",
      "7. S\n",
      "8. K\n",
      "9. A\n",
      "10. N\n",
      "11. N\n",
      "12. A\n",
      "13. N\n",
      "\n",
      "There are 13 letters in \"Shathis Kannan\".\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
